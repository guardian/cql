Logs for examples of queries: https://logs.gutools.co.uk/s/content-platforms/app/discover#/?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:now-15m,to:now))&_a=(columns:!(request),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:b0be43a0-59d7-11e8-a75a-b7af20e8f748,key:Name,negate:!f,params:(query:Kong-PROD),type:phrase),query:(match_phrase:(Name:Kong-PROD)))),index:b0be43a0-59d7-11e8-a75a-b7af20e8f748,interval:auto,query:(language:kuery,query:%2Fsearch),sort:!(!('@timestamp',desc)))

We should sample e.g. 200 queries and translate them into CQL.

Toy examples:

sausages
"hot dog" OR "hottest dog"
"hot dog" +tag:dogs -tags:food
"hot dog" +section:film
"hot dog" +from:2024-01-12 +to:2024-02-12

Grammar:

query              -> (search_expr)* EOF
search_expr        -> (search_str | quoted_search_str | search_param)
quoted_search_str  -> '"' string '"'
basic_search_str   -> /\w/
search_param       -> '+' search_key ':' search_value
search_key         -> 'tag' | 'section' | ...etc
search_value       -> /\w/

How do we disambiguate search params from strings in the tokeniser?
Or is '+tag:', '+section:' the lexeme, not '+' 'tag' ':'?

Scanning tokens – should + (or :) be its own token, or part of search param token? No – there's no context where they're used in another combination, we can think of them as assymetrical quote marks for a particular token type.

Should search_key or search_value be recognised as tokens, or just the literals ':', '+' and strings – you can then build the grammar from '+' string ':' string? No – +tag:hai and +tag: hai would parse as the same thing, which would be incorrect. Search key/value pairs and their separators are contiguous.

